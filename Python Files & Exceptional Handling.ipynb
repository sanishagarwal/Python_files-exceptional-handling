{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __*Python Files & Exceptional Handling*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where  multiprocessing is a better choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Scenarios Where Multithreading is Preferable to Multiprocessing and Vice Versa__\n",
    "\n",
    "### When **Multithreading** is Preferable:\n",
    "\n",
    "Multithreading involves running multiple threads within the same process. It is suitable in scenarios where tasks involve **I/O-bound** operations, such as file reading/writing, network requests, or database querying, where threads spend a lot of time waiting for data to be read or written.\n",
    "\n",
    "1. **I/O-bound tasks**:\n",
    "   - **Scenario**: When a program is reading data from a disk, querying a database, or sending/receiving data over the network.\n",
    "   - **Why multithreading**: Threads can run concurrently, allowing one thread to handle I/O operations while others continue processing. This leads to more efficient use of resources since I/O-bound tasks spend much of their time waiting for input/output, rather than utilizing the CPU.\n",
    "\n",
    "2. **Shared memory tasks**:\n",
    "   - **Scenario**: If the tasks require frequent sharing and access to the same data, like updating a shared data structure (e.g., a cache).\n",
    "   - **Why multithreading**: Threads share the same memory space, so communication between threads is easier and faster than between processes. This avoids the overhead of inter-process communication (IPC) needed in multiprocessing.\n",
    "\n",
    "3. **Lower memory overhead**:\n",
    "   - **Scenario**: When you want to perform concurrent tasks but memory usage is a concern.\n",
    "   - **Why multithreading**: Threads within the same process share the same memory space, leading to lower memory overhead compared to creating multiple processes, which each have their own memory space.\n",
    "\n",
    "4. **Lightweight parallelism**:\n",
    "   - **Scenario**: If the program requires lightweight parallelism, such as managing multiple small tasks like GUI responsiveness or handling multiple user inputs.\n",
    "   - **Why multithreading**: Threads are lighter and take up less memory compared to processes, making them better suited for lightweight tasks.\n",
    "\n",
    "---\n",
    "\n",
    "### When **Multiprocessing** is Preferable:\n",
    "\n",
    "Multiprocessing involves running multiple processes, each with its own memory space. It is best suited for **CPU-bound** tasks that require heavy computation and can take advantage of multiple cores on a machine.\n",
    "\n",
    "1. **CPU-bound tasks**:\n",
    "   - **Scenario**: When a program performs tasks that require heavy computation, such as mathematical computations, data analysis, image processing, or simulations.\n",
    "   - **Why multiprocessing**: Since each process runs in its own memory space and on its own CPU core, it allows true parallelism on multi-core systems. This leads to better performance for CPU-intensive tasks because processes do not compete for the same CPU resources.\n",
    "\n",
    "2. **Avoiding Global Interpreter Lock (GIL)** (in Python):\n",
    "   - **Scenario**: When you are working with CPU-bound tasks in Python, which has a Global Interpreter Lock (GIL) limiting the execution of Python bytecode to one thread at a time.\n",
    "   - **Why multiprocessing**: Multiprocessing bypasses the GIL since each process has its own Python interpreter and memory space, allowing them to run on different CPU cores simultaneously without being restricted by the GIL.\n",
    "\n",
    "3. **Isolation between tasks**:\n",
    "   - **Scenario**: When tasks need to run independently and should not affect each other’s memory or data.\n",
    "   - **Why multiprocessing**: Each process runs in its own memory space, which prevents memory corruption or data interference between tasks. This isolation is useful in cases where task failures should not affect other running tasks.\n",
    "\n",
    "4. **Fault tolerance**:\n",
    "   - **Scenario**: If one task may fail or crash, but you need other tasks to keep running.\n",
    "   - **Why multiprocessing**: Since processes are independent, a failure in one process won’t affect the others, providing better fault isolation compared to multithreading, where a failure in one thread can potentially crash the entire program.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- **Multithreading** is preferable for I/O-bound tasks, tasks with frequent memory sharing, lightweight parallelism, and scenarios with low memory overhead.\n",
    "- **Multiprocessing** is better for CPU-bound tasks, avoiding the Python GIL, scenarios requiring task isolation, and when fault tolerance is necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Describe what a process pool is and how it helps in managing multiple processes efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __What is a Process Pool and How It Helps in Managing Multiple Processes Efficiently__\n",
    "\n",
    "A **process pool** is a collection of worker processes that are created and managed to execute tasks in parallel. It is used to efficiently handle multiple processes by reusing the same processes for multiple tasks, reducing the overhead of creating and destroying processes repeatedly.\n",
    "\n",
    "When dealing with many tasks that can be executed in parallel, creating a separate process for each task can be costly in terms of time and resources. A process pool solves this by maintaining a pool of pre-created processes, which are available to perform tasks as soon as they are submitted. When a task is assigned, an available process from the pool is used to execute it. Once the task is done, the process becomes available again for the next task.\n",
    "\n",
    "### Benefits of Process Pools:\n",
    "\n",
    "1. **Reduced overhead**:                                  \n",
    "    Since the same set of processes is reused, there is no need to constantly create and destroy processes, which saves time and memory.\n",
    "2. **Better resource management**:                                                 \n",
    "    The number of processes in the pool can be limited, preventing the system from being overwhelmed by too many concurrent processes.\n",
    "3. **Simplified parallelism**:                                                     \n",
    "    The process pool abstracts the complexity of managing multiple processes, allowing developers to focus on the logic of tasks rather than on process management.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explain what multiprocessing is and why it is used in Python programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __What is Multiprocessing and Why It Is Used in Python Programs__\n",
    "\n",
    "**Multiprocessing** is a programming technique where multiple processes are executed simultaneously, each running in its own independent memory space. In Python, multiprocessing is used to run multiple tasks in parallel, allowing programs to take full advantage of multi-core processors and improve performance, especially for CPU-bound tasks.\n",
    "\n",
    "Python's default threading model has a limitation called the **Global Interpreter Lock (GIL)**, which prevents multiple threads from executing Python bytecode at the same time. This limits the use of multithreading for CPU-bound tasks. Multiprocessing overcomes this limitation by creating separate processes, each with its own Python interpreter and memory space. This allows true parallelism since each process runs independently on different CPU cores without interference from the GIL.\n",
    "\n",
    "### Why Multiprocessing is Used in Python:\n",
    "\n",
    "1. **Improve performance for CPU-bound tasks**:                                              \n",
    "    Tasks like numerical computation, image processing, or simulations can be spread across multiple CPU cores, reducing execution time.\n",
    "2. **Achieve true parallelism**:                                                  \n",
    "    Since each process has its own interpreter, multiprocessing allows parallel execution of Python code, which is not possible with multithreading due to the GIL.\n",
    "3. **Task isolation**:                                            \n",
    "    Each process runs independently, so if one process crashes, it does not affect other processes, improving fault tolerance.\n",
    "4. **Efficient resource utilization**:                                    \n",
    "    By using multiple cores, multiprocessing ensures that the full computational power of the machine is utilized, making programs more efficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 0 to the list\n",
      "Removed 0 from the list\n",
      "Added 1 to the list\n",
      "Added 2 to the list\n",
      "Removed 1 from the list\n",
      "Added 3 to the list\n",
      "Removed 2 from the list\n",
      "Added 4 to the list\n",
      "Removed 3 from the list\n",
      "Removed 4 from the list\n",
      "Final list: []\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "# Shared list between threads\n",
    "numbers = []\n",
    "\n",
    "# Lock object to prevent race conditions\n",
    "lock = threading.Lock()\n",
    "\n",
    "# Function to add numbers to the list\n",
    "def add_numbers():\n",
    "    for i in range(5):\n",
    "        time.sleep(1)\n",
    "        lock.acquire()  # Acquire the lock before modifying the list\n",
    "        numbers.append(i)\n",
    "        print(f\"Added {i} to the list\")\n",
    "        lock.release()  # Release the lock after modification\n",
    "\n",
    "# Function to remove numbers from the list\n",
    "def remove_numbers():\n",
    "    for i in range(5):\n",
    "        time.sleep(1.5)\n",
    "        lock.acquire()  # Acquire the lock before modifying the list\n",
    "        if numbers:\n",
    "            removed = numbers.pop(0)\n",
    "            print(f\"Removed {removed} from the list\")\n",
    "        else:\n",
    "            print(\"List is empty, nothing to remove\")\n",
    "        lock.release()  # Release the lock after modification\n",
    "\n",
    "# Create threads for adding and removing numbers\n",
    "t1 = threading.Thread(target=add_numbers)\n",
    "t2 = threading.Thread(target=remove_numbers)\n",
    "\n",
    "# Start the threads\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "# Wait for both threads to complete\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "print(\"Final list:\", numbers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Explanation:__\n",
    "- Thread 1 (add_numbers) adds numbers from 0 to 4 to a shared list, one number every second.\n",
    "- Thread 2 (remove_numbers) attempts to remove numbers from the list every 1.5 seconds.\n",
    "- A lock (threading.Lock()) is used to prevent both threads from modifying the list at the same time, which avoids race conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Describe the methods and tools available in Python for safely sharing data between threads and processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Python provides several methods and tools for safely sharing data between threads and processes. For threads, the most common challenge is preventing race conditions, and for processes, the challenge is sharing data between isolated memory spaces. Below are the most widely used methods and tools for both threads and processes:\n",
    "\n",
    "### __*1. Threading: Safely Sharing Data Between Threads*__\n",
    "\n",
    "In multithreading, threads share the same memory space, so they have access to the same data. However, this can lead to race conditions where multiple threads try to access or modify shared data simultaneously. Python offers several mechanisms to prevent this:\n",
    "\n",
    "### 1.1 `threading.Lock`\n",
    "A lock is used to ensure that only one thread can access shared data at a time. It is acquired by one thread, and other threads must wait until the lock is released.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock = threading.Lock()\n",
    "lock.acquire()\n",
    "# critical section (modify shared data)\n",
    "lock.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 `threading.RLock`\n",
    "A reentrant lock allows a thread to acquire the same lock multiple times. This is useful when a thread needs to access shared data through recursive function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlock = threading.RLock()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 `threading.Semaphore`\n",
    "A semaphore allows a certain number of threads to access a resource simultaneously, which can be useful for managing limited resources like database connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "semaphore = threading.Semaphore(value=2)  # Allows 2 threads at a time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 `threading.Event`\n",
    "An event is used for communication between threads. It allows one thread to signal other threads to stop or start execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = threading.Event()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 `threading.Condition`\n",
    "Conditions are used to wait for certain conditions to be met before a thread proceeds. They allow threads to wait until some event occurs in another thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = threading.Condition()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __*2. Multiprocessing: Safely Sharing Data Between Processes*__\n",
    "Processes do not share memory space by default, so sharing data between them requires special mechanisms. Python provides tools for this in the multiprocessing module:\n",
    "\n",
    "### 2.1 `multiprocessing.Queue`\n",
    "A queue allows data to be safely shared between processes. One process can add data to the queue, and another process can retrieve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Queue\n",
    "queue = Queue()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 `multiprocessing.Manager`\n",
    "A Manager provides a way to create shared objects, such as lists, dictionaries, and namespaces, that can be safely accessed by multiple processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Manager\n",
    "manager = Manager()\n",
    "shared_list = manager.list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 `multiprocessing.Value and Array`\n",
    "These are low-level constructs that allow sharing simple data types (like integers or arrays) between processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Value, Array\n",
    "shared_value = Value('i', 0)  # Shared integer\n",
    "shared_array = Array('i', [0, 1, 2])  # Shared array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 `multiprocessing.Lock`\n",
    "Just like threading, multiprocessing has a lock mechanism to ensure that only one process can access shared data at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Lock\n",
    "lock = Lock()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 `multiprocessing.Pipe`\n",
    "Pipes provide a two-way communication channel between two processes, allowing them to send and receive data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pipe\n",
    "parent_conn, child_conn = Pipe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __*3. Shared Memory with `multiprocessing.shared_memory`*__\n",
    "This feature, introduced in Python 3.8, allows processes to share large amounts of data more efficiently by using shared memory, which avoids the overhead of pickling and unpickling data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import shared_memory\n",
    "shm = shared_memory.SharedMemory(create=True, size=1024)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __*4. Concurrent Futures: Abstracting Thread and Process Pools*__\n",
    "Python's concurrent.futures module provides a high-level interface for managing thread and process pools using ThreadPoolExecutor and ProcessPoolExecutor. It abstracts away much of the complexity involved in managing threads and processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread result: 0\n",
      "Thread result: 1\n",
      "Thread result: 4\n",
      "Thread result: 9\n",
      "Thread result: 16\n",
      "An error occurred: A process in the process pool was terminated abruptly while the future was running or pending.\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "import time\n",
    "\n",
    "# Define a sample task function\n",
    "def task_function(x):\n",
    "    time.sleep(1)  # Simulate a time-consuming task\n",
    "    return x * x\n",
    "\n",
    "# Using ThreadPoolExecutor\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    futures = [executor.submit(task_function, i) for i in range(5)]\n",
    "    for future in futures:\n",
    "        print(f\"Thread result: {future.result()}\")  # Get and print the result\n",
    "\n",
    "# Using ProcessPoolExecutor\n",
    "try:\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        futures = [executor.submit(task_function, i) for i in range(5)]\n",
    "        for future in futures:\n",
    "            print(f\"Process result: {future.result()}\")  # Get and print the result\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Explanation:__\n",
    "- **Define a Task Function:**                                        \n",
    "    The task_function is defined to perform a simple operation (in this case, squaring the input after a delay).\n",
    "- **Using ThreadPoolExecutor:**                                                    \n",
    "    A ThreadPoolExecutor is created to manage a pool of threads. You can specify the maximum number of threads using the max_workers parameter.\n",
    "- **Submitting Tasks:**                                          \n",
    "    The executor.submit() method is used to submit tasks to the executor. A list comprehension is used to submit multiple tasks.\n",
    "- **Error Handling:**                                                 \n",
    "    Added a try-except block around the ProcessPoolExecutor code to catch exceptions and print them.\n",
    "- **Task Function Simplicity:**                                        \n",
    "    Ensure that task_function is simple, takes basic data types (like integers), and returns a value that is easily picklable.\n",
    "- **Getting Results:**                                             \n",
    "    You can retrieve results using future.result(), which blocks until the result is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for  doing so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __*Importance of Exception Handling in Concurrent Programs:*__\n",
    "1. __Stability and Reliability:__                                                 \n",
    "    Concurrent programs often involve multiple threads or processes running simultaneously. If one thread or process encounters an unhandled exception, it can lead to unexpected behavior, crashes, or resource leaks that may compromise the stability of the entire application.\n",
    "\n",
    "2. __Graceful Degradation:__                                              \n",
    "    Proper exception handling allows programs to fail gracefully. Instead of crashing entirely, the application can catch exceptions and either recover from them or provide meaningful error messages to the user, allowing for continued operation or an orderly shutdown.\n",
    "\n",
    "3. __Resource Management:__                                         \n",
    "    In concurrent programming, resources such as file handles, database connections, and memory must be managed carefully. An exception that goes unhandled could prevent the release of these resources, leading to resource exhaustion or deadlocks.\n",
    "\n",
    "4. __Debugging and Logging:__                     \n",
    "    Exception handling facilitates better debugging. By catching exceptions, developers can log errors, providing insight into what went wrong during execution. This information is invaluable for troubleshooting and fixing issues in concurrent environments.\n",
    "\n",
    "5. __Inter-Thread/Process Communication:__\n",
    "    In concurrent programs, threads and processes often communicate with each other. If one fails and exceptions aren't handled, it could disrupt communication, causing other threads or processes to receive invalid data or experience unexpected states.\n",
    "\n",
    "### __*Techniques for Handling Exceptions in Concurrent Programs:*__\n",
    "\n",
    "1. __Try-Except Blocks:__                                                 \n",
    "    Use `try-except` blocks within your threads or processes to catch and handle exceptions. This ensures that any exceptions raised in a thread or process can be managed locally, allowing for appropriate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: division by zero\n"
     ]
    }
   ],
   "source": [
    "def task_function():\n",
    "    try:\n",
    "        # Example code that could raise an exception\n",
    "        result = 10 / 0  # This will raise a ZeroDivisionError\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Call the function to see the exception handling in action\n",
    "task_function()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Explanation:__\n",
    "- Indentation:                                                         \n",
    "    The line result = 10 / 0 is indented within the try block. If you remove the indentation or don't provide any code at all, you'll receive an IndentationError.\n",
    "- Exception Handling:                                                    \n",
    "    The except block is also indented and will execute if an exception occurs in the try block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Future Result Handling:__                                                         \n",
    "    When using concurrent.futures, you can catch exceptions raised in a thread or process by checking the result of the Future object. Use the result() method to retrieve the result and handle exceptions if they occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: division by zero\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future = executor.submit(task_function)\n",
    "    try:\n",
    "        result = future.result()  # This will raise the exception if it occurred\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in the thread: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. __Custom Exception Classes:__                                                           \n",
    "    Define custom exception classes to handle specific error conditions more effectively. This allows for more granular error handling and helps to identify issues in concurrent tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomError(Exception):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. __Using Callbacks:__                                 \n",
    "    In some frameworks, you can use callbacks that execute when a task completes. This can be used to handle results or exceptions after the task execution.\n",
    "\n",
    "5. __Logging:__                                     \n",
    "    Implement logging mechanisms to record exceptions and other runtime information. This can help monitor the health of your application and diagnose issues in production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:An error occurred\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\baidy\\AppData\\Local\\Temp\\ipykernel_1064\\1549552233.py\", line 8, in <module>\n",
      "    result = 10 / 0  # This will raise a ZeroDivisionError\n",
      "             ~~~^~~\n",
      "ZeroDivisionError: division by zero\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Configure logging to display error messages\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "try:\n",
    "    # Code that may raise an exception\n",
    "    result = 10 / 0  # This will raise a ZeroDivisionError\n",
    "except Exception as e:\n",
    "    # Log the error with traceback information\n",
    "    logging.error(\"An error occurred\", exc_info=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. __Thread-Safe Data Structures:__                                                    \n",
    "    Use thread-safe data structures (like those provided in the queue module) to handle shared data between threads. They often include mechanisms to handle exceptions internally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.  Use `concurrent.futures.ThreadPoolExecutor` to manage the threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The factorial of 4 is 24\n",
      "The factorial of 8 is 40320\n",
      "The factorial of 1 is 1\n",
      "The factorial of 7 is 5040\n",
      "The factorial of 3 is 6\n",
      "The factorial of 5 is 120\n",
      "The factorial of 6 is 720\n",
      "The factorial of 9 is 362880\n",
      "The factorial of 2 is 2\n",
      "The factorial of 10 is 3628800\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import math\n",
    "\n",
    "# Function to calculate the factorial of a number\n",
    "def factorial(n):\n",
    "    return math.factorial(n)\n",
    "\n",
    "# Main function to execute the threading\n",
    "def main():\n",
    "    # Create a ThreadPoolExecutor\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # Submit tasks to calculate factorials for numbers 1 to 10\n",
    "        futures = {executor.submit(factorial, i): i for i in range(1, 11)}\n",
    "        \n",
    "        # Retrieve and print the results as they complete\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            number = futures[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                print(f\"The factorial of {number} is {result}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating factorial of {number}: {e}\")\n",
    "\n",
    "# Entry point for the program\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "1. __Function Definition:__                                                 \n",
    "    - The factorial function takes a number n as an argument and returns its factorial using the math.factorial function.\n",
    "\n",
    "2. __Main Function:__                              \n",
    "    - The main() function creates a ThreadPoolExecutor using a context manager (with statement), ensuring that resources are cleaned up after use.                                          \n",
    "    - A dictionary comprehension is used to submit tasks to the executor for numbers 1 through 10. Each task calculates the factorial of a number.                                              \n",
    "    - The futures dictionary maps each Future object (returned by executor.submit) to its corresponding number.\n",
    "3. __Result Retrieval:__                                     \n",
    "    - The concurrent.futures.as_completed() function is used to iterate over the completed futures. This allows you to retrieve results as they are completed rather than waiting for all tasks to finish.                                   \n",
    "    - For each completed future, it retrieves the result and prints the factorial. If an exception occurs, it catches it and prints an error message.\n",
    "\n",
    "4. __Entry Point:__                                       \n",
    "    - The if __name__ == \"__main__\": block ensures that the main() function is called when the script is executed directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in  parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8  processes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool Size: 2, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time Taken: 5.0045 seconds\n",
      "Pool Size: 4, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time Taken: 3.0020 seconds\n",
      "Pool Size: 8, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time Taken: 2.0019 seconds\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "# Function to compute the square of a number\n",
    "def square(n):\n",
    "    time.sleep(1)  # Simulate a time-consuming task\n",
    "    return n * n\n",
    "\n",
    "# Function to perform the parallel computation\n",
    "def compute_squares(pool_size):\n",
    "    numbers = list(range(1, 11))\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=pool_size) as executor:\n",
    "            results = list(executor.map(square, numbers))\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred with pool size {pool_size}: {e}\")\n",
    "        return []\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Pool Size: {pool_size}, Results: {results}, Time Taken: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "# Main execution block to run the computations with different pool sizes\n",
    "def main():\n",
    "    pool_sizes = [2,4,8]  # Start with a smaller pool size\n",
    "    for size in pool_sizes:\n",
    "        compute_squares(size)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Explanation__\n",
    "1. __Imports:__                                                              \n",
    "    - The code imports the necessary libraries: `concurrent.futures` for managing thread pools and time for measuring execution `time`.\n",
    "\n",
    "2. __Square Function:__                                         \n",
    "    - `square(n)`: A function that takes a number, simulates a delay (1 second), and returns its square.\n",
    "\n",
    "3. __Compute Squares Function:__                                \n",
    "    - `compute_squares(pool_size)`: \n",
    "        - Creates a list of numbers from 1 to 10.\n",
    "        - Records the start time.\n",
    "        - Uses `ThreadPoolExecutor` to execute the `square` function in parallel for each number.\n",
    "        - Catches and prints any exceptions that occur during execution.\n",
    "        - Calculates and prints the results and the time taken for the computation.\n",
    "4. __Main Function:__\n",
    "    - `main()`: Iterates through different thread pool sizes (2, 4, and 8) and calls `compute_squares` for each size.\n",
    "\n",
    "5. __Execution:__\n",
    "    - The if `__name__ == \"__main__\"` block ensures that `main()` runs when the script is executed directly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
